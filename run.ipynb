{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Invarian Point Attention Pytorch Implementation (IPA)</h4>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>This tutorial aims at clarifying the architecture of IPA piece by piece. The IPA module first used by Deepmind team in alphafold2 paper. It was used for coordinate refinement. But in this note book we only implement the attention part of the IPA module. We will see the rest of the module by noteebooks.</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h5>Supplementary Figure</h5>\n",
    "<img src='asset/IPA_Supplementary_Figure.PNG' />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h5>Algorithm</h5>\n",
    "<img src='asset/IPA_algorithm.png' />"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>The definition below is all about the dimension of the attention blocks</p>\n",
    "<ol>\n",
    "<li>nh = number of heads, c = channel dimension, nqp = number of query points, npv = number of point values</li>\n",
    "<li>embd = embedding dimension</li>\n",
    "<li>nqs, nvs = number of query and value dimension for scalar q,k,v definition</li>\n",
    "<li>bias in the linear projection of the q, k, v</li>\n",
    "<li>rpr = require pair representation</li>\n",
    "</ol>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "emdb, nh, c, nqp, npv, nqs, nvs, bias, rpr = 768, 12, 16, 4, 4, 16, 16, False, True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>scalar qkv definition for algorithm line 1.</p>\n",
    "<p>As I highlighted with the arrow in the supplementary figure. We need to define number of contribution of attention weights. Three (with pair representation) or 2 without pair representation.</p>\n",
    "<p>nal - number of attention logits</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "nal = 3 if rpr else 2\n",
    "\n",
    "qs = nn.Linear(emdb, nqs*nh, bias=bias)\n",
    "ks = nn.Linear(emdb, nqs*nh, bias=bias)\n",
    "vs = nn.Linear(emdb, nvs*nh, bias=bias)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>qkv projection for point attention (coordinate and orientation aware) for algorithm line 2</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "qp = nn.Linear(emdb, nqp*nh, bias=bias)\n",
    "kp = nn.Linear(emdb, nqp*nh, bias=bias)\n",
    "vp = nn.Linear(emdb, npv*nh, bias=bias)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>IPA docs from alphafold paper about weight initialization</p>\n",
    "<img src='asset/IPA_docs.png' width=75%/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>defining gama (softplus of learnable scalar) -> point weight initial value(pwiv) to define point weights (pw) </p>\n",
    "<img src='asset/softplus_function.png' />"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "pwiv = torch.log(torch.exp(torch.full((12,), 1.))  + 1.)\n",
    "pw = nn.Parameter(pwiv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#scalar_attn_logits_scale\n",
    "sals = (nal * nqs) ** -0.5\n",
    "#point_attn_logits_scale\n",
    "pals = ((nal * nqp) * (9 / 2)) ** -0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#implementing line 4\n",
    "bij = nn.Linear()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "my-rdkit-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
